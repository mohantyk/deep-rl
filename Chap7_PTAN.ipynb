{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chap7-PTAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPD+BMoTBgJMzfv/peVVTa6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohantyk/deep-rl/blob/master/Chap7_PTAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzhuNR4cDpEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "58b77335-10c3-41d6-c65e-d078b1a68b8d"
      },
      "source": [
        "!pip install ptan"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ptan\n",
            "  Using cached https://files.pythonhosted.org/packages/91/cb/57f6d86625f2b24c008b0524ca29559683aa75d00afa38b6b44d7fcad25b/ptan-0.6.tar.gz\n",
            "Collecting torch==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from ptan) (0.17.2)\n",
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.6/dist-packages (from ptan) (0.2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ptan) (1.18.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from ptan) (4.1.2.30)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py->ptan) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->ptan) (0.16.0)\n",
            "Building wheels for collected packages: ptan\n",
            "  Building wheel for ptan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptan: filename=ptan-0.6-cp36-none-any.whl size=23502 sha256=9cbdf8b4a5a0f77c08953a4e4e50b61667f558c45ab4f56523ce76c068bfd789\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/4b/2f/9a45fd39b0a614a2716bc6128a7f1adb4647f323a2d90783f2\n",
            "Successfully built ptan\n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, ptan\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed ptan-0.6 torch-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFp3PSTlDxlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import ptan\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdRC8DqqHig7",
        "colab_type": "text"
      },
      "source": [
        "## Action Selectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Q31OXfGUFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "652b5c8f-f0cf-4948-8fa5-d76e54cd8491"
      },
      "source": [
        "q_vals = np.array([[1,2, 3],\n",
        "                   [1, -1, 0]]) # dim 0 is batch\n",
        "selector = ptan.actions.ArgmaxActionSelector()\n",
        "selector(q_vals) # Returns indices of actions with largest values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZYdsGppGxYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a563b59-9963-4f3f-dfdd-b8641ebb366a"
      },
      "source": [
        "epsgreedy = ptan.actions.EpsilonGreedyActionSelector(1)\n",
        "epsgreedy(q_vals)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxPb23WnHB05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "36a9b54a-9a31-4e89-b735-c4042fa49166"
      },
      "source": [
        "prob_selector = ptan.actions.ProbabilityActionSelector()\n",
        "for _ in range(10):\n",
        "  q_val_distrib = np.array([[0.1, 0.8, 0.1],\n",
        "                            [0.0, 0.0, 1.0],\n",
        "                            [0.5, 0.5, 0.0]])\n",
        "  acts = prob_selector(q_val_distrib)\n",
        "  print(acts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 1]\n",
            "[1 2 0]\n",
            "[2 2 0]\n",
            "[1 2 0]\n",
            "[2 2 1]\n",
            "[1 2 1]\n",
            "[1 2 0]\n",
            "[1 2 1]\n",
            "[2 2 0]\n",
            "[1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk4aJ8FVHlt1",
        "colab_type": "text"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMcXdhWyJmm-",
        "colab_type": "text"
      },
      "source": [
        "## DQNAgent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYhPo6hHa5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNNet(torch.nn.Module):\n",
        "  def __init__(self, actions: int):\n",
        "    super().__init__()\n",
        "    self.actions = actions\n",
        "\n",
        "  def forward(self, x):\n",
        "    batches = x.shape[0]\n",
        "    return torch.eye(batches, self.actions)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTh6uJRUKFnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8df680d3-c9fc-405a-a6b9-443f7f4e94dc"
      },
      "source": [
        "net = DQNNet(actions=3)\n",
        "obsv = torch.zeros(2,8)\n",
        "q_vals = net(obsv)\n",
        "print(q_vals)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx60G5rmKXqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63405a49-5473-4b9a-d5b0-fe776b2ef735"
      },
      "source": [
        "selector = ptan.actions.ArgmaxActionSelector()\n",
        "agent = ptan.agent.DQNAgent(dqn_model=net, action_selector=selector)\n",
        "agent(obsv) # tuple (best_actions, list of agent's internal state)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), [None, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAAEA-wEK19j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a228abe-dae6-419a-8a4f-c16e3734b5f7"
      },
      "source": [
        "selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=1.0)\n",
        "agent = ptan.agent.DQNAgent(dqn_model=net, action_selector=selector)\n",
        "agent(obsv)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2, 2]), [None, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTXsWBy4LQU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfb3438a-f30b-45ef-c39d-0d2ab144c0f9"
      },
      "source": [
        "selector.epsilon=0.0\n",
        "agent(obsv)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), [None, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AULI3nmLen9",
        "colab_type": "text"
      },
      "source": [
        "## PolicyAgent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skHH_DPTLbIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PolicyNet(torch.nn.Module):\n",
        "  def __init__(self, actions: int):\n",
        "    super().__init__()\n",
        "    self.actions = actions\n",
        "\n",
        "  def forward(self,x):\n",
        "    batches = x.shape[0]\n",
        "    res = torch.zeros(batches, self.actions)\n",
        "    # Make logits of first two actions equal\n",
        "    res[:,0] = 1\n",
        "    res[:,1] = 1\n",
        "    return res"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cYAqnOQMENj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e02779db-9833-4e50-b497-541d9faf54f0"
      },
      "source": [
        "net = PolicyNet(actions=5)\n",
        "obsv = torch.zeros(6, 10)\n",
        "q_vals = net(obsv)\n",
        "print(q_vals)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBLQqUZhMNm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad59f8ce-370f-4241-ecd7-facc4b52be21"
      },
      "source": [
        "selector = ptan.actions.ProbabilityActionSelector()\n",
        "agent = ptan.agent.PolicyAgent(model=net, action_selector=selector, \n",
        "                               apply_softmax=True)\n",
        "agent(obsv) # Softmax produces non-zero probabilities for zero logits"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 0, 1, 4, 2, 4]), [None, None, None, None, None, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpeuTbUxJUaN",
        "colab_type": "text"
      },
      "source": [
        "# Experience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgKqax7ZCzX",
        "colab_type": "text"
      },
      "source": [
        "## Experience Source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRggUjBYQRMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List, Optional, Any, Tuple"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuFs2wh_I2SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToyEnv(gym.Env):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.observation_space = gym.spaces.Discrete(5)\n",
        "    self.action_space = gym.spaces.Discrete(3)\n",
        "    self.step_index = 0\n",
        "\n",
        "  def reset(self):\n",
        "    self.step_index = 0\n",
        "    return self.step_index\n",
        "\n",
        "  def step(self, action):\n",
        "    is_done = self.step_index == 10\n",
        "    if is_done:\n",
        "      return self.step_index % self.observation_space.n, 0.0, is_done, {}\n",
        "    self.step_index += 1\n",
        "    return self.step_index % self.observation_space.n, float(action), \\\n",
        "          self.step_index == 10, {}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e50GM0k5MUjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DullAgent(ptan.agent.BaseAgent):\n",
        "  def __init__(self, action):\n",
        "    self.action = action\n",
        "\n",
        "  def __call__(self, observation: List[Any], \n",
        "               state: Optional[List] = None) -> Tuple[List[int], Optional[List]]:\n",
        "    return [self.action for _ in observation], state"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skKexty1RA8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a9f59e0b-8d97-4bf4-a89f-76870942f4ba"
      },
      "source": [
        "env = ToyEnv()\n",
        "agent = DullAgent(action=1)\n",
        "exp_source = ptan.experience.ExperienceSource(env, agent, steps_count=3)\n",
        "\n",
        "for idx, exp in enumerate(exp_source):\n",
        "  if idx > 15:\n",
        "    break\n",
        "  print(exp)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
            "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
            "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False))\n",
            "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False))\n",
            "(Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
            "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
            "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=True))\n",
            "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=True))\n",
            "(Experience(state=4, action=1, reward=1.0, done=True),)\n",
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
            "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
            "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False))\n",
            "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False))\n",
            "(Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTvGIgvDRjC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "3c53bf75-a5c1-43d0-927b-927ab263e82b"
      },
      "source": [
        "env = ToyEnv()\n",
        "agent = DullAgent(action=1)\n",
        "exp_source = ptan.experience.ExperienceSource([ToyEnv(), ToyEnv()], agent, steps_count=2)\n",
        "\n",
        "for idx, exp in enumerate(exp_source):\n",
        "  if idx > 10:\n",
        "    break\n",
        "  print(exp)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
            "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
            "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
            "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
            "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
            "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False))\n",
            "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False))\n",
            "(Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False))\n",
            "(Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False))\n",
            "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGAyS7vbZHGE",
        "colab_type": "text"
      },
      "source": [
        "## First Last"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i16hIEHX7Z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a19adcbb-825d-4e44-8b52-1953ce4760c8"
      },
      "source": [
        "env = ToyEnv()\n",
        "agent = DullAgent(action=1)\n",
        "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=1.0, steps_count=2)\n",
        "\n",
        "for idx, exp in enumerate(exp_source):\n",
        "  if idx > 10:\n",
        "    break\n",
        "  print(exp)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ExperienceFirstLast(state=0, action=1, reward=2.0, last_state=2)\n",
            "ExperienceFirstLast(state=1, action=1, reward=2.0, last_state=3)\n",
            "ExperienceFirstLast(state=2, action=1, reward=2.0, last_state=4)\n",
            "ExperienceFirstLast(state=3, action=1, reward=2.0, last_state=0)\n",
            "ExperienceFirstLast(state=4, action=1, reward=2.0, last_state=1)\n",
            "ExperienceFirstLast(state=0, action=1, reward=2.0, last_state=2)\n",
            "ExperienceFirstLast(state=1, action=1, reward=2.0, last_state=3)\n",
            "ExperienceFirstLast(state=2, action=1, reward=2.0, last_state=4)\n",
            "ExperienceFirstLast(state=3, action=1, reward=2.0, last_state=None)\n",
            "ExperienceFirstLast(state=4, action=1, reward=1.0, last_state=None)\n",
            "ExperienceFirstLast(state=0, action=1, reward=2.0, last_state=2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqGYaNARaBGa",
        "colab_type": "text"
      },
      "source": [
        "## Replay Buffers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFljYpe9ZgUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "143796b7-568d-4002-b32b-fcd982edb2d7"
      },
      "source": [
        "env = ToyEnv()\n",
        "agent = DullAgent(action=1)\n",
        "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, 1.0, 1)\n",
        "buffer = ptan.experience.ExperienceReplayBuffer(exp_source, 100)\n",
        "len(buffer)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWdVQHSUa9pn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f909d995-820b-4b20-e930-7f985e311b99"
      },
      "source": [
        "for step in range(6):\n",
        "  buffer.populate(1)\n",
        "  if len(buffer) < 5:\n",
        "    continue\n",
        "  batch = buffer.sample(4)\n",
        "  print(f'{len(batch)} samples')\n",
        "  for exp in batch:\n",
        "    print(exp)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 samples\n",
            "ExperienceFirstLast(state=3, action=1, reward=1.0, last_state=4)\n",
            "ExperienceFirstLast(state=3, action=1, reward=1.0, last_state=4)\n",
            "ExperienceFirstLast(state=4, action=1, reward=1.0, last_state=0)\n",
            "ExperienceFirstLast(state=2, action=1, reward=1.0, last_state=3)\n",
            "4 samples\n",
            "ExperienceFirstLast(state=1, action=1, reward=1.0, last_state=2)\n",
            "ExperienceFirstLast(state=4, action=1, reward=1.0, last_state=0)\n",
            "ExperienceFirstLast(state=1, action=1, reward=1.0, last_state=2)\n",
            "ExperienceFirstLast(state=2, action=1, reward=1.0, last_state=3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALwc1Wxzc4Aa",
        "colab_type": "text"
      },
      "source": [
        "# TargetNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqq_h1A_bX3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ff = torch.nn.Linear(5, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.ff(x)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNOc0QandcUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a7fa526d-c631-4f65-fbb4-9ca3e4a53472"
      },
      "source": [
        "net = DQNNet()\n",
        "print(net)\n",
        "tgt_net = ptan.agent.TargetNet(net)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DQNNet(\n",
            "  (ff): Linear(in_features=5, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aILT6KatdhOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4ac89cef-0170-4057-f360-e53f3b3f116f"
      },
      "source": [
        "net.ff.weight"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0735, -0.1188, -0.4290, -0.1933, -0.4243],\n",
              "        [ 0.0902, -0.1623,  0.0039, -0.3567, -0.0139],\n",
              "        [-0.0377,  0.2571, -0.4437, -0.0462,  0.3738]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWQ6tRu1dxcp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cd06c64c-c8aa-492b-8922-9db343e95a90"
      },
      "source": [
        "tgt_net.target_model.ff.weight"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0735, -0.1188, -0.4290, -0.1933, -0.4243],\n",
              "        [ 0.0902, -0.1623,  0.0039, -0.3567, -0.0139],\n",
              "        [-0.0377,  0.2571, -0.4437, -0.0462,  0.3738]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVvR0Vq6d0ka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "de88844c-7aee-4de3-d092-39608d206e15"
      },
      "source": [
        "net.ff.weight.data += 1.\n",
        "net.ff.weight"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1.0735, 0.8812, 0.5710, 0.8067, 0.5757],\n",
              "        [1.0902, 0.8377, 1.0039, 0.6433, 0.9861],\n",
              "        [0.9623, 1.2571, 0.5563, 0.9538, 1.3738]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wthFcFkd-Mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4ca5ac36-c49b-42a9-82c9-18e351a80cf2"
      },
      "source": [
        "tgt_net.target_model.ff.weight"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0735, -0.1188, -0.4290, -0.1933, -0.4243],\n",
              "        [ 0.0902, -0.1623,  0.0039, -0.3567, -0.0139],\n",
              "        [-0.0377,  0.2571, -0.4437, -0.0462,  0.3738]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsTc9BFXeGoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2bc7a3b1-ebfa-4209-ea9f-07ef44715da4"
      },
      "source": [
        "tgt_net.sync()\n",
        "tgt_net.target_model.ff.weight"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1.0735, 0.8812, 0.5710, 0.8067, 0.5757],\n",
              "        [1.0902, 0.8377, 1.0039, 0.6433, 0.9861],\n",
              "        [0.9623, 1.2571, 0.5563, 0.9538, 1.3738]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb6UgeQeKUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}